{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atebah/Viewers/blob/master/VIDA_MONAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j0cMB24NDUF"
      },
      "source": [
        "# installations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-GZ8pVOkwZRt",
        "outputId": "c48ee2ca-b267-4b63-da5c-fca8095b62c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,788 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,965 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,685 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,540 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,126 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,770 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,241 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,081 kB]\n",
            "Fetched 28.6 MB in 3s (9,648 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.11 is already the newest version (3.11.11-1+jammy1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.11\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbulYBIsdxaA",
        "outputId": "a2a9f632-280c-4011-a305-9bbb0082126c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kZlPhWa9V8ls",
        "outputId": "ec629481-6546-42a2-93e9-a88eedd0aa92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gdcm\n",
            "  Downloading gdcm-1.1-py3-none-manylinux1_x86_64.whl.metadata (167 bytes)\n",
            "Downloading gdcm-1.1-py3-none-manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.7 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gdcm\n",
            "Successfully installed gdcm-1.1\n",
            "Collecting pylibjpeg\n",
            "  Downloading pylibjpeg-2.0.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting pylibjpeg-libjpeg\n",
            "  Downloading pylibjpeg_libjpeg-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pylibjpeg) (2.0.2)\n",
            "Downloading pylibjpeg-2.0.1-py3-none-any.whl (24 kB)\n",
            "Downloading pylibjpeg_libjpeg-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pylibjpeg-libjpeg, pylibjpeg\n",
            "Successfully installed pylibjpeg-2.0.1 pylibjpeg-libjpeg-2.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gdcm\n",
        "!pip install pylibjpeg pylibjpeg-libjpeg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UGvLUT0G5Jfi",
        "outputId": "b8832ad3-6dbb-430c-b4b2-751e6ea4cc85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting highdicom\n",
            "  Downloading highdicom-0.25.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.11/dist-packages (from highdicom) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8.3 in /usr/local/lib/python3.11/dist-packages (from highdicom) (11.1.0)\n",
            "Collecting pydicom>=3.0.1 (from highdicom)\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting pyjpegls>=1.0.0 (from highdicom)\n",
            "  Downloading pyjpegls-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from highdicom) (4.13.0)\n",
            "Downloading highdicom-0.25.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyjpegls-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyjpegls, pydicom, highdicom\n",
            "Successfully installed highdicom-0.25.1 pydicom-3.0.1 pyjpegls-1.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install highdicom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "IyHqZg36NBEd",
        "outputId": "dbed8593-f4fd-4fc3-ec08-54bca1f4afcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai-deploy-app-sdk\n",
            "  Downloading monai_deploy_app_sdk-2.0.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from monai-deploy-app-sdk) (2.0.2)\n",
            "Collecting holoscan~=2.0 (from monai-deploy-app-sdk)\n",
            "  Downloading holoscan-2.9.0-cp311-cp311-manylinux_2_35_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting colorama>=0.4.1 (from monai-deploy-app-sdk)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: typeguard>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from monai-deploy-app-sdk) (4.4.2)\n",
            "Requirement already satisfied: pip>22.0.2 in /usr/local/lib/python3.11/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk) (24.1.2)\n",
            "Requirement already satisfied: cupy-cuda12x<14.0,>=12.2 in /usr/local/lib/python3.11/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk) (13.3.0)\n",
            "Collecting numpy>=1.21.6 (from monai-deploy-app-sdk)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<4.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk) (3.1.1)\n",
            "Collecting python-on-whales<1.0,>=0.60.1 (from holoscan~=2.0->monai-deploy-app-sdk)\n",
            "  Downloading python_on_whales-0.76.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: Jinja2<4.0,>=3.1.3 in /usr/local/lib/python3.11/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk) (3.1.6)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk) (24.2)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk) (6.0.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk) (2.32.3)\n",
            "Collecting psutil<7.0,>=6.0.0 (from holoscan~=2.0->monai-deploy-app-sdk)\n",
            "  Downloading psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting wheel-axle-runtime<1.0 (from holoscan~=2.0->monai-deploy-app-sdk)\n",
            "  Downloading wheel_axle_runtime-0.0.6-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from typeguard>=3.0.0->monai-deploy-app-sdk) (4.13.0)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x<14.0,>=12.2->holoscan~=2.0->monai-deploy-app-sdk) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4.0,>=3.1.3->holoscan~=2.0->monai-deploy-app-sdk) (3.0.2)\n",
            "Requirement already satisfied: pydantic!=2.0.*,<3,>=2 in /usr/local/lib/python3.11/dist-packages (from python-on-whales<1.0,>=0.60.1->holoscan~=2.0->monai-deploy-app-sdk) (2.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31.0->holoscan~=2.0->monai-deploy-app-sdk) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31.0->holoscan~=2.0->monai-deploy-app-sdk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31.0->holoscan~=2.0->monai-deploy-app-sdk) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31.0->holoscan~=2.0->monai-deploy-app-sdk) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from wheel-axle-runtime<1.0->holoscan~=2.0->monai-deploy-app-sdk) (3.18.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0,>=0.60.1->holoscan~=2.0->monai-deploy-app-sdk) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0,>=0.60.1->holoscan~=2.0->monai-deploy-app-sdk) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0,>=0.60.1->holoscan~=2.0->monai-deploy-app-sdk) (0.4.0)\n",
            "Downloading monai_deploy_app_sdk-2.0.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading holoscan-2.9.0-cp311-cp311-manylinux_2_35_x86_64.whl (41.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_on_whales-0.76.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.4/115.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel_axle_runtime-0.0.6-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: wheel-axle-runtime, psutil, numpy, colorama, python-on-whales, holoscan, monai-deploy-app-sdk\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyjpegls 1.5.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pylibjpeg-libjpeg 2.3.0 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 holoscan-2.9.0 monai-deploy-app-sdk-2.0.0 numpy-1.26.4 psutil-6.1.1 python-on-whales-0.76.1 wheel-axle-runtime-0.0.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              },
              "id": "3c77cd7372634b87b14a6a26f56e3b25"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install monai-deploy-app-sdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P0eKSg57Ni31",
        "outputId": "bd4b8e12-f24e-451d-965a-3f87fa6b43a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n",
            "Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, monai\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed monai-1.4.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install monai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2b92AErZtxWd",
        "outputId": "6a9540ff-23d9-4ffa-cb13-11d2e0211d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CalcificationDetection'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 11 (delta 1), reused 0 (delta 0), pack-reused 7 (from 1)\u001b[K\n",
            "Receiving objects: 100% (11/11), 6.90 MiB | 10.76 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/roeez/CalcificationDetection.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiwSXzAGpcc8"
      },
      "outputs": [],
      "source": [
        "!rm -rf dcm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOELxOBfuhtX"
      },
      "outputs": [],
      "source": [
        "!mkdir dcm input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG7ERS6cuGS_",
        "outputId": "76b97d9e-911b-43a5-e633-df8ab530dcc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: HOLOSCAN_INPUT_PATH=input\n",
            "env: HOLOSCAN_MODEL_PATH=/content/models/model/model.ts\n",
            "env: HOLOSCAN_OUTPUT_PATH=output\n"
          ]
        }
      ],
      "source": [
        "%env HOLOSCAN_INPUT_PATH input\n",
        "%env HOLOSCAN_MODEL_PATH /content/models/model/model.ts\n",
        "%env HOLOSCAN_OUTPUT_PATH output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLmCVBllW8sJ"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import glob\n",
        "dcm_path = glob.glob(\"/content/drive/MyDrive/vida/DICOM_data/*\")\n",
        "for dcm in dcm_path:\n",
        "  shutil.copy(dcm,\"/content/input\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9qu1TcPt0kk"
      },
      "source": [
        "# convert model.pth to torchscript model.ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIK_0qUuxf8s"
      },
      "outputs": [],
      "source": [
        "# !mkdir \"/content/output\" \"/content/output/saved_images_folder\" \"/content/model\"\n",
        "!mkdir \"/content/models\" \"/content/models/model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZltFwpyBuNod"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class CBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CBlock, self).__init__()\n",
        "        assert out_channels % 4 == 0\n",
        "        self.conv3 = nn.Conv2d(in_channels, out_channels//4, 3, padding=3//2)\n",
        "        self.conv5 = nn.Conv2d(in_channels, out_channels//4, 5, padding=5//2)\n",
        "        self.conv7 = nn.Conv2d(in_channels, out_channels//4, 7, padding=7//2)\n",
        "        self.conv9 = nn.Conv2d(in_channels, out_channels//4, 9, padding=9//2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(torch.cat([self.conv3(x), self.conv5(x), self.conv7(x), self.conv9(x)], 1)))\n",
        "\n",
        "class NetC(nn.Module):\n",
        "    def __init__(self, tag, kernel_size=9, skip_connections=True, batch_norm=True, kernel_depth_seed=4, network_depth=4, act_func=nn.ReLU(),\n",
        "                 initializer=None):\n",
        "        super(NetC, self).__init__()\n",
        "        self.tag = tag\n",
        "        self.block1 = CBlock(1, 4)\n",
        "        self.block2 = CBlock(4, 16)\n",
        "        self.block3 = CBlock(16, 32)\n",
        "        self.block4 = CBlock(32, 64)\n",
        "        self.block5 = CBlock(64, 128)\n",
        "        self.pred = nn.Conv2d(128, 1, 5, padding=5//2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "        return self.pred(x)\n",
        "\n",
        "model = NetC(tag='encoder')\n",
        "if torch.cuda.is_available():\n",
        "  model.load_state_dict(torch.load(\"/content/CalcificationDetection/C__00900.weights\"))\n",
        "else:\n",
        "  model.load_state_dict(torch.load(\"/content/CalcificationDetection/C__00900.weights\",map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "# Create dummy input (match your model input shape)\n",
        "dummy_input = torch.randn(1, 1, 224, 224)  # Modify based on your model\n",
        "\n",
        "# Convert to TorchScript using tracing\n",
        "traced_model = torch.jit.trace(model, dummy_input)\n",
        "\n",
        "# Save the model\n",
        "traced_model.save(\"/content/models/model/model.ts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHPCVPG-NOKk"
      },
      "source": [
        "# Operator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nspwjWkLNRxD"
      },
      "outputs": [],
      "source": [
        "# for classifer\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, Optional\n",
        "\n",
        "import torch\n",
        "\n",
        "from monai.data import DataLoader, Dataset\n",
        "from monai.deploy.core import AppContext, ConditionType, Fragment, Image, Operator, OperatorSpec\n",
        "from monai.deploy.operators.monai_seg_inference_operator import InMemImageReader\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    Compose,\n",
        "    EnsureChannelFirst,\n",
        "    EnsureType,\n",
        "    LoadImage,\n",
        "    NormalizeIntensity,\n",
        "    RepeatChannel,\n",
        "    Resize,\n",
        "    SqueezeDim,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdcHgE8Gyjl8"
      },
      "outputs": [],
      "source": [
        "# for segmentation model\n",
        "from monai.deploy.core import AppContext, ConditionType, Fragment, Operator, OperatorSpec\n",
        "from monai.deploy.operators.monai_seg_inference_operator import InfererType, InMemImageReader, MonaiSegInferenceOperator\n",
        "from monai.transforms import (\n",
        "    Activationsd,\n",
        "    AsDiscreted,\n",
        "    Compose,\n",
        "    CropForegroundd,\n",
        "    EnsureChannelFirstd,\n",
        "    Invertd,\n",
        "    LoadImaged,\n",
        "    ScaleIntensityRanged,\n",
        "    Spacingd,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIVKdObQXW4G"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg9IlKk54aaC"
      },
      "source": [
        "## VIDAReadDcmOperator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbJ2R_eGcleZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4949f978-2fd5-4fc2-e8d1-f336ebb40bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘DCM2PNG’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir DCM2PNG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7ooJYgwQtaY"
      },
      "outputs": [],
      "source": [
        "class VIDAReadDcmOperator (Operator):\n",
        "    DEFAULT_INPUT_FOLDER = Path.cwd() / \"input\"\n",
        "    DEFAULT_OUTPUT_NAME = \"image\"  ## ===> saving output dcm2png to an in-memmory object\n",
        "    DCM2PNG_OUTPUT_FOLDER = Path.cwd() / \"DCM2PNG\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        fragment: Fragment,\n",
        "        *args,\n",
        "        input_folder: Path = DEFAULT_INPUT_FOLDER,\n",
        "        output_name: str = DEFAULT_OUTPUT_NAME,\n",
        "        **kwargs,\n",
        "    ):\n",
        "      self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
        "      self.input_path = input_folder\n",
        "      self.index = 0\n",
        "      self.output_name_image = (\n",
        "          output_name.strip() if output_name and len(output_name.strip()) > 0 else VIDAReadDcmOperator.DEFAULT_OUTPUT_NAME\n",
        "      )\n",
        "      self.output_folder = VIDAReadDcmOperator.DCM2PNG_OUTPUT_FOLDER\n",
        "      self.output_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "      super().__init__(fragment, *args, **kwargs)\n",
        "\n",
        "    def setup(self, spec: OperatorSpec):\n",
        "        \"\"\"Set up the named input and output port(s)\"\"\"\n",
        "        spec.output(self.output_name_image)\n",
        "\n",
        "    def left_mamm(self,mamm):\n",
        "      if mamm[:, :200, ...].sum() < mamm[:, -200:, ...].sum():\n",
        "          mamm[:, :, ...] = mamm[:, ::-1, ...]\n",
        "          print(\"#### left mamm ####\")\n",
        "      return mamm\n",
        "\n",
        "    def cut_mamm(self,mamm, act_w):\n",
        "      h = mamm.shape[0]\n",
        "      mamm = mamm[:h, :act_w]\n",
        "      print(\"#### cut mamm ####\",mamm.shape)\n",
        "      return mamm\n",
        "\n",
        "    def get_act_width(self,mamm):\n",
        "      w = mamm.shape[1] // 3\n",
        "      while mamm[:, w:].max() > 0:\n",
        "          w += 1\n",
        "      print(\"#### get_act_width ####\")\n",
        "      return w\n",
        "\n",
        "    def clean_mamm(self,mamm):\n",
        "      background_val = 0\n",
        "      mamm[:10, :, ...] = 0\n",
        "      mamm[-10:, :, ...] = 0\n",
        "      mamm[:, -10:, ...] = 0\n",
        "      msk1 = (mamm[:, :, 0] == mamm[:, :, 1]) & (mamm[:, :, 1] == mamm[:, :, 2])\n",
        "      mamm = mamm.mean(axis=2) * msk1\n",
        "      msk = np.uint8((mamm > background_val) * 255)\n",
        "      msk = cv2.morphologyEx(msk, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (50, 50)))\n",
        "      comps = cv2.connectedComponentsWithStats(msk)\n",
        "      common_label = np.argmax(comps[2][1:, cv2.CC_STAT_AREA]) + 1\n",
        "      msk = (comps[1] == common_label).astype(np.uint8)\n",
        "      mamm[:, :] = msk * mamm[:, :]\n",
        "      print(\"#### clean mamm ####\")\n",
        "      return mamm\n",
        "\n",
        "    def mamms_preprocess(self,mamm):\n",
        "      print(\"#### preprocess mamm ####\")\n",
        "      mamm = self.left_mamm(mamm)\n",
        "      mamm = self.clean_mamm(mamm)\n",
        "      act_w = self.get_act_width(mamm)\n",
        "      mamm = self.cut_mamm(mamm, act_w)\n",
        "      return mamm\n",
        "\n",
        "    def load_mamm(self,mamm, max_height=0, width=0, encoder=None):\n",
        "      print(\"#### load mamm ####\")\n",
        "      # mamm = cv2.imread(case_path).astype(np.float32) / 255\n",
        "      mamm = mamm.astype(np.float32) / 255\n",
        "      mamm = self.mamms_preprocess(mamm)\n",
        "      return mamm, mamm.shape[1]\n",
        "\n",
        "\n",
        "    def compute(self, op_input, op_output, context):\n",
        "        import numpy as np\n",
        "        import pydicom\n",
        "        import cv2\n",
        "        from torchvision.transforms import ToPILImage\n",
        "        print(\"#######  converting DICOM to numpy array  #######\")\n",
        "\n",
        "        # Input path is stored in the object attribute, but could change to use a named port if need be.\n",
        "        input_path = self.input_path\n",
        "        if input_path.is_dir():\n",
        "            # input_path = next(self.input_path.glob(\"*.*\"))  # take the first file\n",
        "            input_path = os.path.join(\"/content/input\",os.listdir(input_path)[0])\n",
        "\n",
        "        print(f\" the input path is {input_path}\")\n",
        "\n",
        "        ds = pydicom.dcmread(input_path)\n",
        "        image_array = ds.pixel_array\n",
        "        if len(image_array.shape) == 2:\n",
        "          image_array = cv2.cvtColor(image_array, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "        print(\"image shape before preprocess: \", image_array.shape)\n",
        "        ####################  load_mamm  #######################\n",
        "        image_preprocessed, sh = self.load_mamm(image_array)\n",
        "        ########################################################\n",
        "        print(\"#######  DICOM converted  ########\\n\",image_preprocessed)\n",
        "        norm_img = cv2.normalize(image_preprocessed,None,0,255,cv2.NORM_MINMAX, cv2.CV_8U)\n",
        "        cv2.imwrite(\"/content/DCM2PNG/dcm2pmg.png\",norm_img)\n",
        "        # to_pil = ToPILImage()\n",
        "        # pil_image = to_pil(image_preprocessed)\n",
        "        # output_image = Image(image_arr)  # create Image domain object with a numpy array\n",
        "        op_output.emit(image_preprocessed, self.output_name_image)  # cannot omit the name even if single output.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEFsnXnR4cvL"
      },
      "source": [
        "## VIDAoperator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmk_Ie6HPAlV"
      },
      "outputs": [],
      "source": [
        "class VIDAoperator(Operator):\n",
        "  DEFAULT_OUTPUT_FOLDER = Path.cwd() / \"output/saved_images_folder\"\n",
        "  MODEL_LOCAL_PATH = Path(os.environ.get(\"HOLOSCAN_MODEL_PATH\", Path.cwd() / \"model/model.ts\"))\n",
        "\n",
        "\n",
        "  def __init__(\n",
        "        self,\n",
        "        fragment: Fragment,\n",
        "        *args,\n",
        "        app_context: AppContext,\n",
        "        model_name: Optional[str] = \"\",\n",
        "        model_path: Path = MODEL_LOCAL_PATH,\n",
        "        output_folder: Path = DEFAULT_OUTPUT_FOLDER,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        # the names used for the model inference input and output\n",
        "        self._input_dataset_key = \"image\"\n",
        "        self._pred_dataset_key = \"pred\"\n",
        "\n",
        "        self.model_path = model_path\n",
        "        self.output_folder = output_folder\n",
        "        self.output_folder.mkdir(parents=True, exist_ok=True)\n",
        "        self.app_context = app_context\n",
        "        self.input_name_image = \"image\"\n",
        "        self.output_name_seg = \"seg_image\"\n",
        "        self.output_name_saved_images_folder = \"saved_images_folder\"\n",
        "\n",
        "        # Need the path to load the models when they are not loaded in the execution context\n",
        "        self.tsmodel,self.ptmodel = self._get_model(self.app_context, self.model_path)\n",
        "\n",
        "        # The base class has an attribute called fragment to hold the reference to the fragment object\n",
        "        super().__init__(fragment, *args, **kwargs)\n",
        "\n",
        "  def setup(self, spec: OperatorSpec):\n",
        "        spec.input(self.input_name_image)\n",
        "        spec.output(self.output_name_seg)\n",
        "        spec.output(self.output_name_saved_images_folder).condition(ConditionType.NONE)\n",
        "\n",
        "\n",
        "  def _get_model(self, app_context: AppContext, model_path: Path):\n",
        "      \"\"\"Load the model from context or file and set the predictor function.\"\"\"\n",
        "      print(\"======  getting the model  =======\")\n",
        "      from CalcificationDetection.core import NetC\n",
        "      pt_model = NetC(tag='encoder')\n",
        "      pt_model.eval()\n",
        "\n",
        "      # Load the PyTorch model\n",
        "      ts_model = torch.jit.load(\n",
        "          \"/content/models/model/model.ts\",\n",
        "          map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "      )\n",
        "\n",
        "      pt_model.load_state_dict(torch.load('/content/CalcificationDetection/C__00900.weights',\n",
        "                                                         map_location=next(model.parameters()).device, weights_only=True))\n",
        "\n",
        "\n",
        "      return ts_model,pt_model\n",
        "\n",
        "  def compute(self, op_input, op_output, context:AppContext):\n",
        "\n",
        "      import torch\n",
        "      import numpy as np\n",
        "      from torchvision.transforms import ToPILImage\n",
        "      import cv2\n",
        "      from CalcificationDetection.core import predict\n",
        "\n",
        "      print(\"===== Passing image to the model =====\")\n",
        "\n",
        "\n",
        "      # Receive the image object (assuming it's in monai.deploy.core.domain.image.Image format)\n",
        "      numpy_image: Image = op_input.receive(self.input_name_image)\n",
        "\n",
        "      print(\"In-memory image received shape: \", numpy_image.shape)\n",
        "\n",
        "      # If it's a single channel image, remove the batch dimension (if present)\n",
        "      if numpy_image.ndim == 3 and numpy_image.shape[0] == 1:\n",
        "          numpy_image = numpy_image.squeeze(0)\n",
        "\n",
        "      print(\"Pil image is: \",numpy_image)\n",
        "\n",
        "      # Perform inference using the wrapped model\n",
        "      with torch.no_grad():\n",
        "          prediction,raw_out = predict(self.ptmodel,numpy_image)  # Calls the predictor function\n",
        "      print(f\"======  this is model raw output: {raw_out}\")\n",
        "\n",
        "      # Check the shape of the prediction\n",
        "      print(f\"Prediction shape: {prediction.shape}\")\n",
        "\n",
        "      # prediction = prediction.squeeze(0)  # Remove batch dimension if it's present\n",
        "      prediction_norm =  cv2.normalize(prediction,None,0,255,cv2.NORM_MINMAX, cv2.CV_8U)\n",
        "      cv2.imwrite(\"/content/DCM2PNG/test.png\",prediction_norm)\n",
        "\n",
        "      op_output.emit(prediction, self.output_name_seg)\n",
        "      op_output.emit(self.output_folder, self.output_name_saved_images_folder)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9yZiZBChuU0"
      },
      "source": [
        "## PNGConverterOperator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpU1K5u5SQud"
      },
      "outputs": [],
      "source": [
        "# Copyright 2021-2023 MONAI Consortium\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "from os import getcwd, makedirs\n",
        "from os.path import join\n",
        "from pathlib import Path\n",
        "from typing import Union\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from monai.deploy.core import Fragment, Image, Operator, OperatorSpec\n",
        "from monai.deploy.operators.dicom_data_loader_operator import DICOMDataLoaderOperator\n",
        "from monai.deploy.operators.dicom_series_to_volume_operator import DICOMSeriesToVolumeOperator\n",
        "from monai.deploy.utils.importutil import optional_import\n",
        "\n",
        "PILImage, _ = optional_import(\"PIL\", name=\"Image\")\n",
        "\n",
        "\n",
        "# @md.env(pip_packages=[\"Pillow >= 8.0.0\", \"numpy\"])\n",
        "class PNGConverterOperator(Operator):\n",
        "    \"\"\"\n",
        "    This operator writes out a 3D Volumetric Image to to a file folder in a slice by slice manner.\n",
        "\n",
        "    Named input:\n",
        "        image: Image object or numpy ndarray\n",
        "\n",
        "    Named output:\n",
        "        None\n",
        "\n",
        "    File output:\n",
        "        Generated PNG image file(s) saved in the provided output folder.\n",
        "    \"\"\"\n",
        "\n",
        "    # The default output folder for saving the generated DICOM instance file.\n",
        "    DEFAULT_OUTPUT_FOLDER = Path(getcwd()) / \"output/saved_images_folder\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        fragment: Fragment,\n",
        "        *args,\n",
        "        output_folder: Union[str, Path],\n",
        "        **kwargs,\n",
        "    ):\n",
        "        print(\"########  PNG Converter Operator   ########\")\n",
        "\n",
        "        self.output_folder = output_folder if output_folder else PNGConverterOperator.DEFAULT_OUTPUT_FOLDER\n",
        "        self.input_name_image = \"image\"\n",
        "        # Need to call the base class constructor last\n",
        "        super().__init__(fragment, *args, **kwargs)\n",
        "\n",
        "    def setup(self, spec: OperatorSpec):\n",
        "        spec.input(self.input_name_image)\n",
        "\n",
        "    def compute(self, op_input, op_output, context):\n",
        "        input_image = op_input.receive(self.input_name_image)\n",
        "        self.output_folder.mkdir(parents=True, exist_ok=True)\n",
        "        self.convert_and_save(input_image, self.output_folder)\n",
        "\n",
        "    def convert_and_save(self, image, path):\n",
        "        \"\"\"\n",
        "        extracts the slices in originally acquired direction (often axial)\n",
        "        and saves them in PNG format slice by slice in the specified directory\n",
        "        \"\"\"\n",
        "        print(\"########  PNG Converter Operator   ########\")\n",
        "        rgb_image = None\n",
        "        if isinstance(image, Image):\n",
        "            image_data = image.asnumpy()\n",
        "            pil_image = PILImage.fromarray(image_data)\n",
        "            if pil_image.mode != \"RGB\":\n",
        "              rgb_image = pil_image.convert(\"RGB\")\n",
        "        elif isinstance(image, np.ndarray):\n",
        "            image_data = image\n",
        "            pil_image = PILImage.fromarray(image_data)\n",
        "            if pil_image.mode != \"RGB\":\n",
        "              rgb_image = pil_image.convert(\"RGB\")\n",
        "        else:\n",
        "            raise ValueError(f\"Input is not Image or ndarray, {type(image)}.\")\n",
        "        image_shape = image_data.shape\n",
        "\n",
        "        num_images = image_shape[0]\n",
        "\n",
        "        # for i in range(0, num_images):\n",
        "        #     input_data = image_data[i, :, :]\n",
        "        #     pil_image = PILImage.fromarray(input_data)\n",
        "        #     if pil_image.mode != \"RGB\":\n",
        "        #         pil_image = pil_image.convert(\"RGB\")\n",
        "        rgb_image.save(join(str(path),\"model_out_image.png\"))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhaKRdQ36QBV"
      },
      "source": [
        "## MaskGenerationPostprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkbWRu4pxkPV"
      },
      "outputs": [],
      "source": [
        "class MaskGenerationPostprocess (Operator):\n",
        "  def __init__(\n",
        "        self,\n",
        "        fragment: Fragment,\n",
        "        *args,\n",
        "        app_context: AppContext,\n",
        "        **kwargs,\n",
        "  ):\n",
        "        self.input_name_image = \"model_out_image\"\n",
        "        self.output_name_seg = \"mask\"\n",
        "        super().__init__(fragment, *args, **kwargs)\n",
        "\n",
        "  def setup(self, spec: OperatorSpec):\n",
        "      spec.input(self.input_name_image)\n",
        "      spec.output(self.output_name_seg)\n",
        "\n",
        "  def segmentation_map(self,prediction, threshold):\n",
        "      seg_map = prediction.copy()\n",
        "      seg_map[seg_map < threshold] = 0\n",
        "      seg_map[seg_map > 0] = 1\n",
        "      return seg_map * 255\n",
        "\n",
        "  def compute(self, op_input, op_output, context):\n",
        "      import torch\n",
        "      import numpy as np\n",
        "      from torchvision.transforms import ToPILImage\n",
        "\n",
        "      print(\"=====  Mask Generation Postprocess =====\")\n",
        "      # Receive the image object (assuming it's in monai.deploy.core.domain.image.Image format)\n",
        "      numpy_mask: Image = op_input.receive(self.input_name_image)\n",
        "      if len(numpy_mask.shape) > 1:\n",
        "        print(\"Mask shape is : \", numpy_mask.shape)\n",
        "        # If it's a single channel image, remove the batch dimension (if present)\n",
        "      if numpy_mask.ndim == 3 and numpy_mask.shape[0] == 1:\n",
        "            numpy_mask = numpy_mask.squeeze(0)\n",
        "\n",
        "      sm = self.segmentation_map(numpy_mask,0.5)\n",
        "\n",
        "      sh = numpy_mask.shape\n",
        "      if isinstance(sh, tuple):\n",
        "        sh = sh[1]\n",
        "\n",
        "      new_w = numpy_mask.shape[1] - sh\n",
        "\n",
        "      # Add black pixels to the right side of the segmentation map\n",
        "      sm = np.pad(sm, ((0, 0), (0, new_w)), mode='constant', constant_values=0)\n",
        "\n",
        "      original_size = (numpy_mask.shape[1], numpy_mask.shape[0])\n",
        "      sm_resized = cv2.resize(sm, original_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "      print(f\"left sum is {numpy_mask[:,:10].sum()} and right sum is {numpy_mask[:,-10:-1].sum()}\")\n",
        "      if numpy_mask[:,:10].sum() < numpy_mask[:,-10:-1].sum():\n",
        "          # right side image\n",
        "          print(\" ######## Rotatttteeeeee\")\n",
        "          tmp_mask = np.flip(sm_resized,1)\n",
        "      else:\n",
        "          tmp_mask = sm_resized\n",
        "      cv2.imwrite(\"mask.png\",tmp_mask)\n",
        "      op_output.emit(sm_resized,self.output_name_seg)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdDQhTLIMWlT"
      },
      "source": [
        "#App.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpZ2-y98meOD"
      },
      "source": [
        "#### app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hVUwPOfMEJ3"
      },
      "outputs": [],
      "source": [
        "from pydicom.sr.codedict import codes  # Required for setting SegmentDescription attributes.\n",
        "from monai.deploy.conditions import CountCondition\n",
        "from monai.deploy.core import AppContext, Application\n",
        "from monai.deploy.operators.dicom_data_loader_operator import DICOMDataLoaderOperator\n",
        "from monai.deploy.operators.dicom_seg_writer_operator import DICOMSegmentationWriterOperator, SegmentDescription\n",
        "from monai.deploy.operators.dicom_series_selector_operator import DICOMSeriesSelectorOperator\n",
        "from monai.deploy.operators.dicom_series_to_volume_operator import DICOMSeriesToVolumeOperator\n",
        "from monai.deploy.operators.stl_conversion_operator import STLConversionOperator\n",
        "from monai.deploy.operators.dicom_text_sr_writer_operator import DICOMTextSRWriterOperator, EquipmentInfo, ModelInfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUqclz-rMaNY"
      },
      "outputs": [],
      "source": [
        "class VIDA_mask_generation_APP(Application):\n",
        "    def compose(self):\n",
        "        print(\"==== start running app ======\")\n",
        "        app_context = Application.init_app_context({})  # Do not pass argv in Jupyter Notebook\n",
        "        app_input_path = Path(app_context.input_path)\n",
        "        app_output_path = Path(app_context.output_path)\n",
        "        model_path = Path(app_context.model_path)\n",
        "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
        "        load_dcm_op = VIDAReadDcmOperator(self, CountCondition(self, 1), input_folder=app_input_path, name=\"VIDA DICOM LOADER\")\n",
        "        segmentation_op = VIDAoperator(\n",
        "            self, app_context=app_context, output_folder=app_output_path, model_path=model_path, name=\"VIDA MASK GENERATION\")\n",
        "\n",
        "        numpy2png = PNGConverterOperator(self,output_folder= app_output_path,name=\"numpy2png\")\n",
        "        img2mask = MaskGenerationPostprocess(self,app_context=app_context,name = \"img2mask\")\n",
        "\n",
        "        self.add_flow(load_dcm_op, segmentation_op, {(\"image\", \"image\")})\n",
        "        self.add_flow(segmentation_op,img2mask,{(\"seg_image\",\"model_out_image\")})\n",
        "        # self.add_flow(segmentation_op,numpy2png,{(\"seg_image\",\"image\")})\n",
        "        self.add_flow(img2mask,numpy2png,{(\"mask\",\"image\")})\n",
        "\n",
        "        #############################################\n",
        "        # Sample_Rules_Text = \"\"\"\n",
        "        # {\n",
        "        #     \"selections\": [\n",
        "        #         {\n",
        "        #             \"name\": \"calcification\",\n",
        "        #             \"conditions\": {\n",
        "        #                 \"Modality\": \"MG\",\n",
        "        #                 \"ImageType\": [\"DERIVED\", \"SECONDARY\"],\n",
        "        #                 \"PhotometricInterpretation\": \"MONOCHROME2\",\n",
        "        #                 \"PresentationIntentType\": \"FOR PRESENTATION\"\n",
        "        #             }\n",
        "        #         }\n",
        "        #     ]\n",
        "        # }\n",
        "        # \"\"\"\n",
        "\n",
        "\n",
        "        # study_loader_op = DICOMDataLoaderOperator(\n",
        "        #     self, CountCondition(self, 1), input_folder=app_input_path, name=\"dcm_loader_op\"\n",
        "        # )\n",
        "        # series_selector_op = DICOMSeriesSelectorOperator(self, rules=Sample_Rules_Text, name=\"series_selector_op\")\n",
        "        # series_to_vol_op = DICOMSeriesToVolumeOperator(self, name=\"series_to_vol_op\")\n",
        "\n",
        "        # self.add_flow(study_loader_op, series_selector_op, {(\"dicom_study_list\", \"dicom_study_list\")})\n",
        "        # # print(f\"Loaded DICOM studies: {study_loader_op}\")\n",
        "        # self.add_flow(\n",
        "        #     series_selector_op, series_to_vol_op, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
        "        # )\n",
        "        # self.add_flow(series_to_vol_op, segmentation_op, {(\"image\", \"image\")})\n",
        "\n",
        "        #  ###########################################\n",
        "\n",
        "        # _algorithm_name = \"segmentation of the calcification from breast mammogram\"\n",
        "        # _algorithm_family = codes.DCM.ArtificialIntelligence\n",
        "        # _algorithm_version = \"0.1.0\"\n",
        "\n",
        "        # segment_descriptions = [\n",
        "        #     SegmentDescription(\n",
        "        #         segment_label=\"calcification\",\n",
        "        #         segmented_property_category=codes.SCT.Organ,\n",
        "        #         segmented_property_type=codes.SCT.Liver,\n",
        "        #         algorithm_name=_algorithm_name,\n",
        "        #         algorithm_family=_algorithm_family,\n",
        "        #         algorithm_version=_algorithm_version,\n",
        "        #     )\n",
        "        # ]\n",
        "\n",
        "        # dicom_seg_writer = DICOMSegmentationWriterOperator(\n",
        "        #     self, segment_descriptions=segment_descriptions, output_folder=app_output_path, name=\"dcm_seg_writer_op\"\n",
        "        # )\n",
        "\n",
        "        # self.add_flow(load_dcm_op, segmentation_op, {(\"image\", \"image\")})\n",
        "        # self.add_flow(\n",
        "        #     load_dcm_op, dicom_seg_writer, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
        "        # )\n",
        "        # self.add_flow(segmentation_op, dicom_seg_writer, {(\"seg_image\", \"seg_image\")})\n",
        "        self._logger.debug(f\"End {self.compose.__name__}\")\n",
        "        print(\"==== end running app ======\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n54e6tW6miO7"
      },
      "source": [
        "#### run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGGEE8n54AJu",
        "outputId": "05d48a47-3e4f-4077-c06d-e6212ff0dbfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-04-01 11:33:42,643] [INFO] (root) - Parsed args: Namespace(log_level=None, input=None, output=None, model=None, workdir=None, argv=[])\n",
            "[2025-04-01 11:33:42,645] [INFO] (root) - AppContext object: AppContext(input_path=input, output_path=output, model_path=models, workdir=)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== start running app ======\n",
            "======  getting the model  =======\n",
            "########  PNG Converter Operator   ########\n",
            "==== end running app ======\n",
            "#######  converting DICOM to numpy array  #######\n",
            " the input path is /content/input/data8\n",
            "image shape before preprocess:  (3328, 2560, 3)\n",
            "#### load mamm ####\n",
            "#### preprocess mamm ####\n",
            "#### left mamm ####\n",
            "#### clean mamm ####\n",
            "#### get_act_width ####\n",
            "#### cut mamm #### (3328, 1682)\n",
            "#######  DICOM converted  ########\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "===== Passing image to the model =====\n",
            "In-memory image received shape:  (3328, 1682)\n",
            "Pil image is:  [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "model output:  [[ -57.994125  -105.92749   -165.34912   ...   -5.882905    -5.0926633\n",
            "    -4.1485577]\n",
            " [-105.88146   -175.1029    -256.99103   ...   -7.0831194   -6.3279357\n",
            "    -5.2121787]\n",
            " [-117.603584  -198.70837   -299.15222   ...   -9.066761    -7.9347477\n",
            "    -6.641178 ]\n",
            " ...\n",
            " [  -8.084211   -11.552667   -15.196892  ...   -9.000524    -7.698951\n",
            "    -6.66617  ]\n",
            " [  -6.750142    -9.406999   -12.0872345 ...   -8.111277    -7.253333\n",
            "    -6.096675 ]\n",
            " [  -5.452098    -7.1277843   -8.844454  ...   -6.1830215   -5.3481536\n",
            "    -4.517291 ]] torch.Size([1, 1, 3328, 1682])\n",
            "======  this is model raw output: tensor([[[[ -57.9941, -105.9275, -165.3491,  ...,   -5.8829,   -5.0927,\n",
            "             -4.1486],\n",
            "          [-105.8815, -175.1029, -256.9910,  ...,   -7.0831,   -6.3279,\n",
            "             -5.2122],\n",
            "          [-117.6036, -198.7084, -299.1522,  ...,   -9.0668,   -7.9347,\n",
            "             -6.6412],\n",
            "          ...,\n",
            "          [  -8.0842,  -11.5527,  -15.1969,  ...,   -9.0005,   -7.6990,\n",
            "             -6.6662],\n",
            "          [  -6.7501,   -9.4070,  -12.0872,  ...,   -8.1113,   -7.2533,\n",
            "             -6.0967],\n",
            "          [  -5.4521,   -7.1278,   -8.8445,  ...,   -6.1830,   -5.3482,\n",
            "             -4.5173]]]])\n",
            "Prediction shape: (3328, 1682)\n",
            "=====  Mask Generation Postprocess =====\n",
            "Mask shape is :  (3328, 1682)\n",
            "left sum is 24139.955078125 and right sum is 28.036212921142578\n",
            "########  PNG Converter Operator   ########\n"
          ]
        }
      ],
      "source": [
        "# !rm -rf $HOLOSCAN_OUTPUT_PATH\n",
        "app = VIDA_mask_generation_APP()\n",
        "app.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIhIlfNwo5yw",
        "outputId": "d84591d2-929c-4b0f-f163-31950450e787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.11.11\n"
          ]
        }
      ],
      "source": [
        "!python --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7FKbdIrpYSy",
        "outputId": "c01c45c9-68d5-4020-ebce-5df094b2e37b",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Dataset/ai_spleen_seg_bundle_data.zip\n",
            "  inflating: dcm/1-001.dcm           \n",
            "  inflating: dcm/1-002.dcm           \n",
            "  inflating: dcm/1-003.dcm           \n",
            "  inflating: dcm/1-004.dcm           \n",
            "  inflating: dcm/1-005.dcm           \n",
            "  inflating: dcm/1-006.dcm           \n",
            "  inflating: dcm/1-007.dcm           \n",
            "  inflating: dcm/1-008.dcm           \n",
            "  inflating: dcm/1-009.dcm           \n",
            "  inflating: dcm/1-010.dcm           \n",
            "  inflating: dcm/1-011.dcm           \n",
            "  inflating: dcm/1-012.dcm           \n",
            "  inflating: dcm/1-013.dcm           \n",
            "  inflating: dcm/1-014.dcm           \n",
            "  inflating: dcm/1-015.dcm           \n",
            "  inflating: dcm/1-016.dcm           \n",
            "  inflating: dcm/1-017.dcm           \n",
            "  inflating: dcm/1-018.dcm           \n",
            "  inflating: dcm/1-019.dcm           \n",
            "  inflating: dcm/1-020.dcm           \n",
            "  inflating: dcm/1-021.dcm           \n",
            "  inflating: dcm/1-022.dcm           \n",
            "  inflating: dcm/1-023.dcm           \n",
            "  inflating: dcm/1-024.dcm           \n",
            "  inflating: dcm/1-025.dcm           \n",
            "  inflating: dcm/1-026.dcm           \n",
            "  inflating: dcm/1-027.dcm           \n",
            "  inflating: dcm/1-028.dcm           \n",
            "  inflating: dcm/1-029.dcm           \n",
            "  inflating: dcm/1-030.dcm           \n",
            "  inflating: dcm/1-031.dcm           \n",
            "  inflating: dcm/1-032.dcm           \n",
            "  inflating: dcm/1-033.dcm           \n",
            "  inflating: dcm/1-034.dcm           \n",
            "  inflating: dcm/1-035.dcm           \n",
            "  inflating: dcm/1-036.dcm           \n",
            "  inflating: dcm/1-037.dcm           \n",
            "  inflating: dcm/1-038.dcm           \n",
            "  inflating: dcm/1-039.dcm           \n",
            "  inflating: dcm/1-040.dcm           \n",
            "  inflating: dcm/1-041.dcm           \n",
            "  inflating: dcm/1-042.dcm           \n",
            "  inflating: dcm/1-043.dcm           \n",
            "  inflating: dcm/1-044.dcm           \n",
            "  inflating: dcm/1-045.dcm           \n",
            "  inflating: dcm/1-046.dcm           \n",
            "  inflating: dcm/1-047.dcm           \n",
            "  inflating: dcm/1-048.dcm           \n",
            "  inflating: dcm/1-049.dcm           \n",
            "  inflating: dcm/1-050.dcm           \n",
            "  inflating: dcm/1-051.dcm           \n",
            "  inflating: dcm/1-052.dcm           \n",
            "  inflating: dcm/1-053.dcm           \n",
            "  inflating: dcm/1-054.dcm           \n",
            "  inflating: dcm/1-055.dcm           \n",
            "  inflating: dcm/1-056.dcm           \n",
            "  inflating: dcm/1-057.dcm           \n",
            "  inflating: dcm/1-058.dcm           \n",
            "  inflating: dcm/1-059.dcm           \n",
            "  inflating: dcm/1-060.dcm           \n",
            "  inflating: dcm/1-061.dcm           \n",
            "  inflating: dcm/1-062.dcm           \n",
            "  inflating: dcm/1-063.dcm           \n",
            "  inflating: dcm/1-064.dcm           \n",
            "  inflating: dcm/1-065.dcm           \n",
            "  inflating: dcm/1-066.dcm           \n",
            "  inflating: dcm/1-067.dcm           \n",
            "  inflating: dcm/1-068.dcm           \n",
            "  inflating: dcm/1-069.dcm           \n",
            "  inflating: dcm/1-070.dcm           \n",
            "  inflating: dcm/1-071.dcm           \n",
            "  inflating: dcm/1-072.dcm           \n",
            "  inflating: dcm/1-073.dcm           \n",
            "  inflating: dcm/1-074.dcm           \n",
            "  inflating: dcm/1-075.dcm           \n",
            "  inflating: dcm/1-076.dcm           \n",
            "  inflating: dcm/1-077.dcm           \n",
            "  inflating: dcm/1-078.dcm           \n",
            "  inflating: dcm/1-079.dcm           \n",
            "  inflating: dcm/1-080.dcm           \n",
            "  inflating: dcm/1-081.dcm           \n",
            "  inflating: dcm/1-082.dcm           \n",
            "  inflating: dcm/1-083.dcm           \n",
            "  inflating: dcm/1-084.dcm           \n",
            "  inflating: dcm/1-085.dcm           \n",
            "  inflating: dcm/1-086.dcm           \n",
            "  inflating: dcm/1-087.dcm           \n",
            "  inflating: dcm/1-088.dcm           \n",
            "  inflating: dcm/1-089.dcm           \n",
            "  inflating: dcm/1-090.dcm           \n",
            "  inflating: dcm/1-091.dcm           \n",
            "  inflating: dcm/1-092.dcm           \n",
            "  inflating: dcm/1-093.dcm           \n",
            "  inflating: dcm/1-094.dcm           \n",
            "  inflating: dcm/1-095.dcm           \n",
            "  inflating: dcm/1-096.dcm           \n",
            "  inflating: dcm/1-097.dcm           \n",
            "  inflating: dcm/1-098.dcm           \n",
            "  inflating: dcm/1-099.dcm           \n",
            "  inflating: dcm/1-100.dcm           \n",
            "  inflating: dcm/1-101.dcm           \n",
            "  inflating: dcm/1-102.dcm           \n",
            "  inflating: dcm/1-103.dcm           \n",
            "  inflating: dcm/1-104.dcm           \n",
            "  inflating: dcm/1-105.dcm           \n",
            "  inflating: dcm/1-106.dcm           \n",
            "  inflating: dcm/1-107.dcm           \n",
            "  inflating: dcm/1-108.dcm           \n",
            "  inflating: dcm/1-109.dcm           \n",
            "  inflating: dcm/1-110.dcm           \n",
            "  inflating: dcm/1-111.dcm           \n",
            "  inflating: dcm/1-112.dcm           \n",
            "  inflating: dcm/1-113.dcm           \n",
            "  inflating: dcm/1-114.dcm           \n",
            "  inflating: dcm/1-115.dcm           \n",
            "  inflating: dcm/1-116.dcm           \n",
            "  inflating: dcm/1-117.dcm           \n",
            "  inflating: dcm/1-118.dcm           \n",
            "  inflating: dcm/1-119.dcm           \n",
            "  inflating: dcm/1-120.dcm           \n",
            "  inflating: dcm/1-121.dcm           \n",
            "  inflating: dcm/1-122.dcm           \n",
            "  inflating: dcm/1-123.dcm           \n",
            "  inflating: dcm/1-124.dcm           \n",
            "  inflating: dcm/1-125.dcm           \n",
            "  inflating: dcm/1-126.dcm           \n",
            "  inflating: dcm/1-127.dcm           \n",
            "  inflating: dcm/1-128.dcm           \n",
            "  inflating: dcm/1-129.dcm           \n",
            "  inflating: dcm/1-130.dcm           \n",
            "  inflating: dcm/1-131.dcm           \n",
            "  inflating: dcm/1-132.dcm           \n",
            "  inflating: dcm/1-133.dcm           \n",
            "  inflating: dcm/1-134.dcm           \n",
            "  inflating: dcm/1-135.dcm           \n",
            "  inflating: dcm/1-136.dcm           \n",
            "  inflating: dcm/1-137.dcm           \n",
            "  inflating: dcm/1-138.dcm           \n",
            "  inflating: dcm/1-139.dcm           \n",
            "  inflating: dcm/1-140.dcm           \n",
            "  inflating: dcm/1-141.dcm           \n",
            "  inflating: dcm/1-142.dcm           \n",
            "  inflating: dcm/1-143.dcm           \n",
            "  inflating: dcm/1-144.dcm           \n",
            "  inflating: dcm/1-145.dcm           \n",
            "  inflating: dcm/1-146.dcm           \n",
            "  inflating: dcm/1-147.dcm           \n",
            "  inflating: dcm/1-148.dcm           \n",
            "  inflating: dcm/1-149.dcm           \n",
            "  inflating: dcm/1-150.dcm           \n",
            "  inflating: dcm/1-151.dcm           \n",
            "  inflating: dcm/1-152.dcm           \n",
            "  inflating: dcm/1-153.dcm           \n",
            "  inflating: dcm/1-154.dcm           \n",
            "  inflating: dcm/1-155.dcm           \n",
            "  inflating: dcm/1-156.dcm           \n",
            "  inflating: dcm/1-157.dcm           \n",
            "  inflating: dcm/1-158.dcm           \n",
            "  inflating: dcm/1-159.dcm           \n",
            "  inflating: dcm/1-160.dcm           \n",
            "  inflating: dcm/1-161.dcm           \n",
            "  inflating: dcm/1-162.dcm           \n",
            "  inflating: dcm/1-163.dcm           \n",
            "  inflating: dcm/1-164.dcm           \n",
            "  inflating: dcm/1-165.dcm           \n",
            "  inflating: dcm/1-166.dcm           \n",
            "  inflating: dcm/1-167.dcm           \n",
            "  inflating: dcm/1-168.dcm           \n",
            "  inflating: dcm/1-169.dcm           \n",
            "  inflating: dcm/1-170.dcm           \n",
            "  inflating: dcm/1-171.dcm           \n",
            "  inflating: dcm/1-172.dcm           \n",
            "  inflating: dcm/1-173.dcm           \n",
            "  inflating: dcm/1-174.dcm           \n",
            "  inflating: dcm/1-175.dcm           \n",
            "  inflating: dcm/1-176.dcm           \n",
            "  inflating: dcm/1-177.dcm           \n",
            "  inflating: dcm/1-178.dcm           \n",
            "  inflating: dcm/1-179.dcm           \n",
            "  inflating: dcm/1-180.dcm           \n",
            "  inflating: dcm/1-181.dcm           \n",
            "  inflating: dcm/1-182.dcm           \n",
            "  inflating: dcm/1-183.dcm           \n",
            "  inflating: dcm/1-184.dcm           \n",
            "  inflating: dcm/1-185.dcm           \n",
            "  inflating: dcm/1-186.dcm           \n",
            "  inflating: dcm/1-187.dcm           \n",
            "  inflating: dcm/1-188.dcm           \n",
            "  inflating: dcm/1-189.dcm           \n",
            "  inflating: dcm/1-190.dcm           \n",
            "  inflating: dcm/1-191.dcm           \n",
            "  inflating: dcm/1-192.dcm           \n",
            "  inflating: dcm/1-193.dcm           \n",
            "  inflating: dcm/1-194.dcm           \n",
            "  inflating: dcm/1-195.dcm           \n",
            "  inflating: dcm/1-196.dcm           \n",
            "  inflating: dcm/1-197.dcm           \n",
            "  inflating: dcm/1-198.dcm           \n",
            "  inflating: dcm/1-199.dcm           \n",
            "  inflating: dcm/1-200.dcm           \n",
            "  inflating: dcm/1-201.dcm           \n",
            "  inflating: dcm/1-202.dcm           \n",
            "  inflating: dcm/1-203.dcm           \n",
            "  inflating: dcm/1-204.dcm           \n",
            "  inflating: model.ts                \n"
          ]
        }
      ],
      "source": [
        "!unzip -o \"/content/drive/MyDrive/Dataset/ai_spleen_seg_bundle_data.zip\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}